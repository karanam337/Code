{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was the best of times, it was the worst of times, \n",
      "it was the\n",
      "age of wisdom, it was the age of foolishness, it was the epoch of belief,\n",
      "it was the epoch of incredulity, it was the season of Light, \n",
      "it was the\n",
      "season of Darkness, it was the spring of hope, it was the winter of\n",
      "despair, we had everything before us, we had nothing before us, \n",
      "we were\n",
      "all going direct to Heaven, we were all going direct the other way--in\n",
      "short, the period was so far like the present period, \n",
      "that some of its\n",
      "noisiest authorities insisted on its being received, for good or for\n",
      "evil, in the superlative degree of comparison only.\n",
      "\n",
      "There were a king with a large jaw and a queen with a plain face, on the\n",
      "throne of England; there were a king with a large jaw and a queen with\n",
      "a fair face, on the throne of France. \n",
      "In both countries it was clearer\n",
      "than crystal to the lords of the State preserves of loaves and fishes,\n",
      "that things in general were settled for ever.\n",
      "I\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "SEP = '\\t'\n",
    "vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "\n",
    "INPUT = \"\"\"It was the best of times, it was the worst of times, \\nit was the\n",
    "age of wisdom, it was the age of foolishness, it was the epoch of belief,\n",
    "it was the epoch of incredulity, it was the season of Light, \\nit was the\n",
    "season of Darkness, it was the spring of hope, it was the winter of\n",
    "despair, we had everything before us, we had nothing before us, \\nwe were\n",
    "all going direct to Heaven, we were all going direct the other way--in\n",
    "short, the period was so far like the present period, \\nthat some of its\n",
    "noisiest authorities insisted on its being received, for good or for\n",
    "evil, in the superlative degree of comparison only.\\n\n",
    "There were a king with a large jaw and a queen with a plain face, on the\n",
    "throne of England; there were a king with a large jaw and a queen with\n",
    "a fair face, on the throne of France. \\nIn both countries it was clearer\n",
    "than crystal to the lords of the State preserves of loaves and fishes,\n",
    "that things in general were settled for ever.\"\"\"\n",
    "\n",
    "class Mapper(object):\n",
    "    \n",
    "    def __init__(self, stream=INPUT, sep = SEP):\n",
    "        self.stream = stream\n",
    "        self.sep = SEP\n",
    "        self.stop_words = nltk.corpus.stopwords.words('english')\n",
    "        self.punctuation = string.punctuation \n",
    "    \n",
    "    def read(self):\n",
    "        for line in self.stream:\n",
    "            yield line.strip()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        print(self.stream)\n",
    "        for row in self.read():\n",
    "            print(row)\n",
    "            break\n",
    "            yield row\n",
    "            \n",
    "    def normalize(self, token):\n",
    "        return token.lower()\n",
    "    \n",
    "    def exclude(self, token):\n",
    "        return (token in self.stop_words or token in self.punctuation)\n",
    "    \n",
    "    def word_check(self, token):\n",
    "        return (token[:1] in vowels and len(token) > 6)\n",
    "    \n",
    "    def tokenize(self, line):\n",
    "        for token in nltk.wordpunct_tokenize(line):\n",
    "            token = self.normalize(token)\n",
    "            if not self.exclude(token) and self.word_check(token):\n",
    "                yield token\n",
    "    \n",
    "    def emit(self, key, value):\n",
    "        #sys.stdout.write('{0}{1}{2}\\n'.format(key,self.sep,value))\n",
    "        print('{0}{1}{2}\\n'.format(key,self.sep,value))\n",
    "        \n",
    "    def mapping(self):\n",
    "        for line in self:\n",
    "            for key in self.tokenize(line):\n",
    "                file_name = 'comedies' # write logic for getting the file name from hadoop streaming\n",
    "                self.emit(key, file_name)         \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mapper = Mapper()\n",
    "    mapper.mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-03a29f634aa3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "a = [[1,2,3],[4,5,6]]\n",
    "a.map(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_relu(x):\n",
    "    return (x >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  ]\n",
      " [-0.1 ]\n",
      " [ 0.85]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train_batch = np.random((32,10))\n",
    "dz_hidden = np.array([[1.0],[-0.1],[0.85]])\n",
    "dz_hidden = dz_hidden.reshape((3,1))\n",
    "print(dz_hidden)\n",
    "\n",
    "da_hidden = derivative_relu(dz_hidden)\n",
    "#dw_input_hidden = x_train_batch.T.dot(da_hidden)\n",
    "da_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
