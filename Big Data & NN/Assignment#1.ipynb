{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ooowisdom\tcomedies\n",
      "\n",
      "epochssss\tcomedies\n",
      "\n",
      "incredulity\tcomedies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "SEP = '\\t'\n",
    "vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "\n",
    "INPUT = ['It was the best of times, it was the worst of times,',\n",
    "         'it was the age of ooowisdom. it was the age of foolishness,',\n",
    "         'it was the epochssss of belief, it was the epoch of incredulity,'] \n",
    "\n",
    "class Mapper(object):\n",
    "    \n",
    "    def __init__(self, stream=INPUT, sep = SEP):\n",
    "        self.stream = stream\n",
    "        self.sep = SEP\n",
    "        self.stop_words = nltk.corpus.stopwords.words('english')\n",
    "        self.punctuation = string.punctuation \n",
    "               \n",
    "    def __iter__(self):\n",
    "        for row in self.stream:\n",
    "            yield row.strip()\n",
    "            \n",
    "    def normalize(self, token):\n",
    "        return token.lower()\n",
    "    \n",
    "    def exclude(self, token):\n",
    "        return (token in self.stop_words or token in self.punctuation)\n",
    "    \n",
    "    def word_check(self, token):\n",
    "        return (token[:1] in vowels and len(token) > 6)\n",
    "    \n",
    "    def tokenize(self, line):\n",
    "        for token in nltk.wordpunct_tokenize(line):\n",
    "            token = self.normalize(token)\n",
    "            if not self.exclude(token) and self.word_check(token):\n",
    "                yield token\n",
    "    \n",
    "    def emit(self, key, value):\n",
    "        #sys.stdout.write('{0}{1}{2}\\n'.format(key,self.sep,value))\n",
    "        print('{0}{1}{2}\\n'.format(key,self.sep,value))   # for testing in jupyter only\n",
    "        \n",
    "    def mapping(self):\n",
    "        for line in self:\n",
    "            for key in self.tokenize(line):\n",
    "                #file_path = os.getenv('map_input_file')\n",
    "                #file_name = file_path.strip().split('/')[-1]\n",
    "                file_name = 'comedies'                    # for testing in jupyter only \n",
    "                self.emit(key, file_name)         \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mapper = Mapper()\n",
    "    mapper.mapping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-7b396f44fb69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'map_input_file'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "file_path = os.getenv('map_input_file')\n",
    "file_name = file_path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doing'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = 'how are you doing'\n",
    "last = temp.split()[-1]\n",
    "last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'word1'\t['comedy', 'love', 'horror']\n",
      "\n",
      "'word2'\t['generic', 'romance', 'horror', 'action', 'comedy']\n",
      "\n",
      "'word4'\t['comedy', 'love', 'horror']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "SEP = '\\t'\n",
    "\n",
    "INPUT = ['word1\\tlove','word1\\tcomedy','word1\\thorror',\n",
    "         'word2\\tromance','word2\\tcomedy','word2\\thorror','word2\\tgeneric','word2\\taction','word2\\tcomedy',\n",
    "         'word4\\tlove','word4\\tcomedy','word4\\thorror'] \n",
    "\n",
    "class Reducer(object):\n",
    "    \n",
    "    def __init__(self, stream=INPUT, sep = SEP):\n",
    "        self.stream = stream\n",
    "        self.sep = SEP \n",
    "               \n",
    "    def __iter__(self):\n",
    "        generator = (line.strip().split(self.sep, 1) for line in self.stream)\n",
    "        for item in groupby(generator, itemgetter(0)):\n",
    "            yield item\n",
    "        \n",
    "    def emit(self, key, value):\n",
    "        #sys.stdout.write(\"'{0}'{1}{2}\\n\".format(key,self.sep,value))\n",
    "        print(\"'{0}'{1}{2}\\n\".format(key, self.sep, value))\n",
    "        \n",
    "    def reduce(self):\n",
    "        for key, group in self:\n",
    "            values = set()\n",
    "            for item in group: \n",
    "                values.add(item[1].strip())\n",
    "                if len(values) == 5:\n",
    "                    break             \n",
    "            self.emit(key, list(values))        \n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    reducer = Reducer()\n",
    "    reducer.reduce()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test', 'string') <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "def check(l):\n",
    "    parts = l.split()\n",
    "    return parts[0], parts[1]  ## it will be returned as a tuple if multiple items are returned\n",
    "\n",
    "test = check('test string')\n",
    "print(test, type(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', <itertools._grouper object at 0x0000019809BB49C8>)\n",
      "a [('a', 1), ('a', 2)]\n",
      "('b', <itertools._grouper object at 0x0000019809BEEF48>)\n",
      "b [('b', 3), ('b', 4)]\n"
     ]
    }
   ],
   "source": [
    "import itertools \n",
    "\n",
    "L = [(\"a\", 1), (\"a\", 2), (\"b\", 3), (\"b\", 4)] \n",
    "\n",
    "# Key function \n",
    "key_func = lambda x: x[0] \n",
    "\n",
    "for group in itertools.groupby(L, key_func): \n",
    "    print(group)\n",
    "    print(group[0], list(group[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a ('a', 'horror') 5\n",
      "'a'\t['horror', 'history', 'comedy', 'love', 'joke']\n",
      "'b'\t['love', 'history', 'comedy', 'joke']\n"
     ]
    }
   ],
   "source": [
    "input = [('a', (('a', 'comedy'), ('a', 'joke'),('a', 'love'),('a', 'history'),('a', 'horror'),('a', 'comedy'))),\n",
    "         ('b', (('b', 'comedy'), ('b', 'joke'),('b', 'love'),('b', 'history')))]\n",
    "\n",
    "for key, group in input:\n",
    "    values = set()\n",
    "    for item in group: \n",
    "        values.add(item[1])\n",
    "        if len(values) == 5:\n",
    "            print(key, item, len(values))\n",
    "            break\n",
    "    print(\"'{}'\\t{}\".format(key, list(values))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['history', 'comedy'], ['history', 'comedy']]\n"
     ]
    }
   ],
   "source": [
    "input = [('a', (('a', 'comedy'), ('a', 'comedy'),('a', 'history'),('a', 'history'))),\n",
    "         ('b', (('b', 'comedy'), ('b', 'history'),('b', 'comedy'),('b', 'history')))]\n",
    "\n",
    "values = [list(set([item[1] for item in group])) for key, group in input]\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ooowisdom\tcomedies\n",
      "\n",
      "epochssss\tcomedies\n",
      "\n",
      "incredulity\tcomedies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import string\n",
    "\n",
    "SEP = '\\t'\n",
    "vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "STOP_WORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \n",
    "              \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \n",
    "              'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', \n",
    "              'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \n",
    "              'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "              'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', \n",
    "              'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', \n",
    "              'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', \n",
    "              'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', \n",
    "              'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', \n",
    "              'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \n",
    "              \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", \n",
    "              'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \n",
    "              \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \n",
    "              \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "INPUT = ['It was the best of times, it was the worst of times,',\n",
    "         'it was the age of ooowisdom. it was the age of foolishness,',\n",
    "         'it was the epochssss of belief, it was the epoch of incredulity,'] \n",
    "\n",
    "class Mapper(object):\n",
    "    \n",
    "    def __init__(self, stream = INPUT, sep = SEP):\n",
    "        self.stream = stream\n",
    "        self.sep = SEP\n",
    "        self.stop_words = STOP_WORDS \n",
    "        self.exclude_chars = string.digits + string.punctuation\n",
    "               \n",
    "    def __iter__(self):\n",
    "        for row in self.stream:\n",
    "            yield row.strip()\n",
    "    \n",
    "    def remove_punct_dig(self, line):\n",
    "        table = str.maketrans(self.exclude_chars, len(self.exclude_chars) * ' ') # in python 2.x its string. instead of str\n",
    "        return line.translate(table)\n",
    "    \n",
    "    def normalize(self, token):\n",
    "        return token.lower()\n",
    "    \n",
    "    def exclude(self, token): \n",
    "        return (token in self.stop_words)\n",
    "    \n",
    "    def word_check(self, token):\n",
    "        return (token[:1] in vowels and len(token) > 6)\n",
    "    \n",
    "    def preprocess(self, line):\n",
    "        line = self.remove_punct_dig(line)\n",
    "        for token in line.split():\n",
    "            token = self.normalize(token)\n",
    "            if not self.exclude(token) and self.word_check(token):\n",
    "                yield token\n",
    "    \n",
    "    def emit(self, key, value):\n",
    "        #sys.stdout.write('{0}{1}{2}\\n'.format(key,self.sep,value))\n",
    "        print('{0}{1}{2}\\n'.format(key,self.sep,value))   # for testing in jupyter only\n",
    "        \n",
    "    def mapping(self):\n",
    "        for line in self:\n",
    "            for key in self.preprocess(line):\n",
    "                #file_path = os.getenv('map_input_file')\n",
    "                #file_name = file_path.strip().split('/')[-1]\n",
    "                file_name = 'comedies'                    # for testing in jupyter only \n",
    "                self.emit(key, file_name)         \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mapper = Mapper()\n",
    "    mapper.mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'word1'\t{'love': 1, 'comedy': 1, 'horror': 1}\n",
      "\n",
      "'word2'\t{'romance': 1, 'comedy': 2, 'horror': 1, 'generic': 1, 'action': 1}\n",
      "\n",
      "'word4'\t{'love': 1, 'comedy': 1, 'horror': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "\n",
    "SEP = '\\t'\n",
    "\n",
    "INPUT = ['word1\\tlove','word1\\tcomedy','word1\\thorror',\n",
    "         'word2\\tromance','word2\\tcomedy','word2\\thorror','word2\\tgeneric','word2\\taction','word2\\tcomedy',\n",
    "         'word4\\tlove','word4\\tcomedy','word4\\thorror'] \n",
    "\n",
    "class Reducer2(object):\n",
    "    \n",
    "    def __init__(self, stream = INPUT, sep = SEP):\n",
    "        self.stream = stream\n",
    "        self.sep = SEP \n",
    "               \n",
    "    def __iter__(self):\n",
    "        generator = (line.strip().split(self.sep, 1) for line in self.stream)\n",
    "        for item in groupby(generator, itemgetter(0)):\n",
    "            yield item\n",
    "        \n",
    "    def emit(self, key, value):\n",
    "        #sys.stdout.write(\"'{0}'{1}{2}\\n\".format(key,self.sep,value))\n",
    "        print(\"'{0}'{1}{2}\\n\".format(key, self.sep, value))\n",
    "        \n",
    "    def reduce(self):\n",
    "        for key, group in self:\n",
    "            values = []\n",
    "            for item in group: \n",
    "                values.append(item[1])\n",
    "            counts = Counter(values)\n",
    "            self.emit(key, dict(counts))        \n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    reducer = Reducer2()\n",
    "    reducer.reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'word1'\t{'comedy': 1, 'horror': 1, 'love': 1}\n",
      "\n",
      "'word2'\t{'generic': 1, 'comedy': 2, 'action': 1, 'horror': 1, 'romance': 1}\n",
      "\n",
      "'word4'\t{'comedy': 1, 'horror': 1, 'love': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "SEP = '\\t'\n",
    "\n",
    "INPUT = ['word1\\tlove','word1\\tcomedy','word1\\thorror',\n",
    "         'word2\\tromance','word2\\tcomedy','word2\\thorror','word2\\tgeneric','word2\\taction','word2\\tcomedy',\n",
    "         'word4\\tlove','word4\\tcomedy','word4\\thorror'] \n",
    "\n",
    "class Reducer2(object):\n",
    "    \n",
    "    def __init__(self, stream = INPUT, sep = SEP):\n",
    "        self.stream = stream\n",
    "        self.sep = SEP \n",
    "               \n",
    "    def __iter__(self):\n",
    "        generator = (line.strip().split(self.sep, 1) for line in self.stream)\n",
    "        for item in groupby(generator, itemgetter(0)):\n",
    "            yield item\n",
    "        \n",
    "    def emit(self, key, value):\n",
    "        #sys.stdout.write(\"'{0}'{1}{2}\\n\".format(key,self.sep,value))\n",
    "        print(\"'{0}'{1}{2}\\n\".format(key, self.sep, value))\n",
    "        \n",
    "    def reduce(self):\n",
    "        for key, group in self:\n",
    "            files = [item[1] for item in group]\n",
    "            file_counts = ((file, files.count(file)) for file in set(files))\n",
    "            self.emit(key, dict(file_counts))        \n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    reducer = Reducer2()\n",
    "    reducer.reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'romance': 1, 'comedy': 2, 'horror': 1, 'generic': 1, 'action': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['romance', 'comedy', 'horror', 'generic', 'action', 'comedy']\n",
    "\n",
    "file_wordcount = {}\n",
    "for item in a:\n",
    "    if item not in file_wordcount:\n",
    "        file_wordcount[item] = 1\n",
    "    else: \n",
    "        file_wordcount[item] += 1\n",
    "\n",
    "file_wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generic': 1, 'comedy': 2, 'action': 1, 'horror': 1, 'romance': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = dict((item, a.count(item)) for item in set(a))\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x000002D924FDCA48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = ((item, a.count(item)) for item in set(a))\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generic': 1, 'comedy': 2, 'action': 1, 'horror': 1, 'romance': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
